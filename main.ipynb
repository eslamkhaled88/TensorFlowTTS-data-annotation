{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbWSPK1C9_uH"
      },
      "source": [
        "### API YouTubeTranscriptApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr4Si-fO9_uJ",
        "outputId": "78edc6c4-6158-4ee0-d08c-277a7702b3ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "can't find file of id named : O-FUZfqchxA\n",
            "2\n",
            "can't find file of id named : kR3Ap2RwiGs\n",
            "3\n",
            "can't find file of id named : YKbf6ODQxs4\n",
            "4\n",
            "can't find file of id named : aoXCXzjHJs8\n",
            "5\n",
            "can't find file of id named : ewg1JMnECp4\n",
            "6\n",
            "can't find file of id named : fJsDmB6iU4E\n",
            "7\n",
            "can't find file of id named : 77Zr8i3SRgw\n",
            "8\n",
            "can't find file of id named : PoUkOOLAmsA\n",
            "9\n",
            "can't find file of id named : cU58BlQjXjI\n",
            "10\n",
            "can't find file of id named : 092zf-iJOxA\n",
            "11\n",
            "can't find file of id named : sXcR6ZvjJFk\n",
            "12\n",
            "can't find file of id named : FA-ymiTqHjg\n",
            "13\n",
            "can't find file of id named : 1RWl9ocxqt8\n",
            "14\n",
            "can't find file of id named : GK8MJi1cERw\n",
            "15\n",
            "can't find file of id named : ceORr737o_s\n",
            "16\n",
            "can't find file of id named : uLOyttpst-o\n",
            "17\n",
            "can't find file of id named : yjgSdVcgStM\n",
            "18\n",
            "can't find file of id named : E07y9D3Q5S0\n",
            "19\n",
            "can't find file of id named : YFnLDeAdnx0\n",
            "20\n",
            "can't find file of id named : gYUMxnSsYao\n",
            "21\n",
            "can't find file of id named : CdRJKZ_L1Xs\n"
          ]
        }
      ],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api.formatters import JSONFormatter\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df = pd.read_excel('youtube.xlsx')\n",
        "\n",
        "def get_jsons_file (data , output_folder):\n",
        "        if not os.path.exists(output_folder):\n",
        "             os.makedirs(output_folder)\n",
        "        count = 0\n",
        "        for i in df['id']:\n",
        "            try:\n",
        "                transcript = YouTubeTranscriptApi.get_transcript(i , languages=['ar'])\n",
        "                formatter = JSONFormatter()\n",
        "                # .format_transcript(transcript) turns the transcript into a JSON string.\n",
        "                json_formatted = formatter.format_transcript(transcript)\n",
        "                with open(os.path.join(output_folder , f'{i}.json' ) , 'w', encoding='utf-8') as json_file:\n",
        "                    json_file.write(json_formatted)\n",
        "            except :\n",
        "                count+=1\n",
        "                print(count)\n",
        "                print(f\"can't find file of id named : {i}\")\n",
        "\n",
        "output_folder = \"transcripts\"\n",
        "\n",
        "get_jsons_file(df , output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpBF40Bp9_uL"
      },
      "source": [
        "### Indivisual Transcription Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azV_dQz59_uL",
        "outputId": "4ef928f8-92c5-479b-88d3-0c5ec1cad7e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing JSON files: 100%|██████████| 221/221 [00:09<00:00, 23.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed in 9.35 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_json_files(folder_path):\n",
        "    start_time = time.time()\n",
        "    output_folder = \"text_files\"\n",
        "\n",
        "    # Check if the output folder exists, create it if it doesn't\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
        "\n",
        "    for file in tqdm(json_files, desc=\"Processing JSON files\"):\n",
        "        text_values = []\n",
        "\n",
        "        with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as json_file:\n",
        "            data = json.load(json_file)\n",
        "            for item in data:\n",
        "                text_value = item.get(\"text\", \"\")\n",
        "                if text_value:\n",
        "                    text_value = text_value + \".\\n\"\n",
        "                    text_values.append(text_value)\n",
        "\n",
        "        output_file_name = os.path.splitext(file)[0] + \".txt\"\n",
        "        with open(os.path.join(output_folder, output_file_name), 'w', encoding='utf-8') as output_file:\n",
        "            output_file.write(' '.join(text_values))\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "# Replace 'your_folder_path_here' with the actual path to the folder containing your JSON files\n",
        "folder_path = 'videos_transcript'\n",
        "process_json_files(folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvvpxCcT9_uL"
      },
      "source": [
        "### *Merge All Transcription in one Line*  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWKn2Qqn9_uL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def merge_text_files(folder_path, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            if file_name.endswith('.txt'):\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                with open(file_path, 'r', encoding='utf-8') as input_file:\n",
        "                    output_file.write(input_file.read())\n",
        "                    output_file.write('\\n')  # Add a newline between the content of each file\n",
        "\n",
        "# Replace 'folder_path' with the actual path to the folder containing your text files\n",
        "folder_path = 'text_files'\n",
        "# Replace 'output_file.txt' with the desired name of the merged output file\n",
        "output_file_path = 'merged_output_file.txt'\n",
        "\n",
        "merge_text_files(folder_path, output_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wZKtupS9_uM"
      },
      "source": [
        "### *Whisper Transcription and Segmentation Pipeline*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyInCdTm9_uM",
        "outputId": "caeddbd6-9a55-4fba-bc14-181b96df9ae9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\menna.essam\\AppData\\Local\\anaconda3\\envs\\whisper\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\menna.essam\\AppData\\Local\\anaconda3\\envs\\whisper\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from faster_whisper import WhisperModel\n",
        "import csv\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import time\n",
        "import torch\n",
        "\n",
        "model_size = \"large-v3\"\n",
        "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "def transcribe_and_segment(audio_path, output_folder_base):\n",
        "    audio_basename = os.path.basename(audio_path).rsplit(\".\", 1)[0]\n",
        "    output_folder = os.path.join(output_folder_base, audio_basename)\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    csv_file_path = os.path.join(output_folder, \"dataset.csv\")\n",
        "\n",
        "    with open(csv_file_path, mode='w', newline='', encoding=\"utf-16\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"id\", \"transcription\", \"start\", \"end\"])\n",
        "\n",
        "        audio_file = AudioSegment.from_file(audio_path)\n",
        "        output_file_id = 1\n",
        "        combined_segments = []\n",
        "        segments, info = model.transcribe(\n",
        "                audio_path,\n",
        "                vad_filter=True,\n",
        "                beam_size=11,  # Reduced beam size\n",
        "                best_of=9,  # Reduced best of\n",
        "                word_timestamps=True,\n",
        "                no_speech_threshold=0.2,\n",
        "                vad_parameters=dict(min_silence_duration_ms=2000),\n",
        "                initial_prompt=\"______________________________________________________________________\",)\n",
        "\n",
        "        for segment in segments:\n",
        "            combined_segments.append(segment)\n",
        "            if len(combined_segments) == 5:\n",
        "                start_time = combined_segments[0].start * 1000\n",
        "                end_time = combined_segments[-1].end * 1003\n",
        "                combined_text = ' '.join([seg.text for seg in combined_segments])\n",
        "                output_segment_filename = f\"{output_file_id}.wav\"\n",
        "                output_segment_path = os.path.join(output_folder, output_segment_filename)\n",
        "\n",
        "                writer.writerow([output_file_id, combined_text, start_time / 1000, end_time / 1000])\n",
        "\n",
        "                segment_audio = audio_file[start_time:end_time]\n",
        "                segment_audio.export(output_segment_path, format=\"wav\")\n",
        "\n",
        "                combined_segments = []\n",
        "                output_file_id += 1\n",
        "                torch.cuda.synchronize()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        if combined_segments:\n",
        "            start_time = combined_segments[0].start * 1000\n",
        "            end_time = combined_segments[-1].end * 1003\n",
        "            combined_text = ' '.join([seg.text for seg in combined_segments])\n",
        "            output_segment_filename = f\"{output_file_id}.wav\"\n",
        "            output_segment_path = os.path.join(output_folder, output_segment_filename)\n",
        "\n",
        "            writer.writerow([output_file_id, combined_text, start_time / 1000, end_time / 1000])\n",
        "\n",
        "            segment_audio = audio_file[start_time:end_time]\n",
        "            segment_audio.export(output_segment_path, format=\"wav\")\n",
        "\n",
        "    print(f\"Transcription of {audio_basename} is Done ...\")\n",
        "\n",
        "def process_assets_folder(assets_folder, output_folder_base):\n",
        "    start_time = time.time()\n",
        "    for file_name in os.listdir(assets_folder):\n",
        "        if file_name.endswith(\".wav\") or file_name.endswith(\".mp3\"):\n",
        "            audio_path = os.path.join(assets_folder, file_name)\n",
        "            transcribe_and_segment(audio_path, output_folder_base)\n",
        "            torch.cuda.synchronize()\n",
        "            torch.cuda.empty_cache()\n",
        "    end_time = time.time()\n",
        "    print(f\"All transcriptions are done. Total time consumption is {(end_time - start_time):.2f} seconds.\")\n",
        "\n",
        "assets_folder = \"Batch_2\"\n",
        "output_folder_base = \"audio_dataset_batch_2\"\n",
        "\n",
        "process_assets_folder(assets_folder, output_folder_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBWyS8Xn9_uL"
      },
      "source": [
        "### *Arabic Text Similarity Analysis with Sentence Transformers*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bli0wfvM9_uL",
        "outputId": "f36ddd8e-4160-4087-fb43-b689b5e7ac94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No sentence-transformers model found with name aubmindlab/bert-base-arabertv2. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most similar sentence to 'فتحتاج زياده االتنم في المئه في نفس السهم.' is:\n",
            "'فتحتاج زياده مئه في المئه في نفس السهم.' with a similarity score of 0.8902\n",
            "فتحتاج - OK\n",
            "زياده - OK\n",
            "االتنم replaced with مئه\n",
            "في - OK\n",
            "المئه - OK\n",
            "في - OK\n",
            "نفس - OK\n",
            "السهم. - OK\n",
            "The most similar sentence to 'اتمنى اذا يعجبكم هذا النوع من المحتوى.' is:\n",
            "'اتمنى اذا يعجبكم هذا النوع من المحتوى.' with a similarity score of 1.0000\n",
            "اتمنى - OK\n",
            "اذا - OK\n",
            "يعجبكم - OK\n",
            "هذا - OK\n",
            "النوع - OK\n",
            "من - OK\n",
            "المحتوى. - OK\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Option 1: mBert model for Arabic (public model, no authentication needed)\n",
        "model_name = 'aubmindlab/bert-base-arabertv2'\n",
        "\n",
        "# Load the model\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "# Function to find the most similar sentence\n",
        "def find_most_similar(target_vector, data_vectors, data_sentences):\n",
        "    highest_similarity = -1\n",
        "    most_similar_sentence = \"\"\n",
        "    for sentence, vector in zip(data_sentences, data_vectors):\n",
        "        similarity = util.pytorch_cos_sim(target_vector, vector)[0][0]\n",
        "        if similarity > highest_similarity:\n",
        "            highest_similarity = similarity\n",
        "            most_similar_sentence = sentence\n",
        "    return most_similar_sentence, highest_similarity\n",
        "\n",
        "# Read the cleaned transcription CSV and select the 'transcription' column\n",
        "df_transcription = pd.read_csv('cleaned_transcription.csv')\n",
        "target_sentences = df_transcription['transcription'].tolist()\n",
        "\n",
        "# Read and clean data sentences\n",
        "full_data_sentences = pd.read_csv('«شي إن» تحقق جولة تاريخية بـ2 مليار دولار _ بودكاست السوق.txt', header=None, sep=\"\\n\", quoting=3)[0].tolist()\n",
        "\n",
        "# Encode data sentences once since they are compared against multiple target sentences\n",
        "data_vectors = model.encode(full_data_sentences)\n",
        "\n",
        "# Prepare a list to hold the results\n",
        "results = []\n",
        "\n",
        "# Iterate through each target sentence, encode, and find the most similar sentence\n",
        "for target_sentence in target_sentences:\n",
        "    target_vector = model.encode([target_sentence])\n",
        "    most_similar_sentence, highest_similarity = find_most_similar(target_vector, data_vectors, full_data_sentences)\n",
        "\n",
        "    # Compare target sentence words with most similar sentence words\n",
        "    comparison_results = []\n",
        "    target_words = target_sentence.split()\n",
        "    similar_words = most_similar_sentence.split()\n",
        "    for i, word in enumerate(target_words):\n",
        "        if i < len(similar_words) and word == similar_words[i]:\n",
        "            comparison_results.append(f\"{word} - OK\")\n",
        "        elif i < len(similar_words):\n",
        "            comparison_results.append(f\"{word} replaced with {similar_words[i]}\")\n",
        "        else:\n",
        "            comparison_results.append(f\"{word} has no match\")\n",
        "\n",
        "    # Store the result including the comparison\n",
        "    results.append({\n",
        "        'Original Sentence': target_sentence,\n",
        "        'Most Similar Sentence': most_similar_sentence,\n",
        "        'Similarity Score': highest_similarity,\n",
        "        'Comparison Results': \" | \".join(comparison_results)  # Joining the comparison results with a separator for better readability in CSV\n",
        "    })\n",
        "\n",
        "# Convert the results into a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "output_file_path = \"similarity_results.csv\"\n",
        "results_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Similarity results saved to '{output_file_path}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Gradio interface for manual revision*"
      ],
      "metadata": {
        "id": "FSMvZ8SrNjqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFFXCkJc9_uM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "csv_path = r'audio_dataset\\assets.csv'\n",
        "voice_data = r'audio_dataset\\voice_data'\n",
        "\n",
        "# Ensure the CSV includes the \"Edited\" and \"Reviewed\" columns\n",
        "def add_columns_to_csv(debug=False):\n",
        "    try:\n",
        "        # Attempt to read the CSV with the specified encoding and 'id' as the index column\n",
        "        df = pd.read_csv(csv_path, index_col='id', encoding='utf-16')\n",
        "    except ValueError as e:\n",
        "        if debug:\n",
        "            print(\"Attempting to read CSV without specifying index_col due to error:\", e)\n",
        "        # Attempt to read the CSV without specifying the index column\n",
        "        df = pd.read_csv(csv_path, encoding='utf-16')\n",
        "        # Check if 'id' column exists\n",
        "        if 'id' not in df.columns:\n",
        "            raise ValueError(\"'id' column not found in CSV. Please verify the file structure.\")\n",
        "\n",
        "    # Proceed with adding 'Edited' and 'Reviewed' columns\n",
        "    if 'Edited' not in df.columns:\n",
        "        df['Edited'] = False\n",
        "    if 'Reviewed' not in df.columns:\n",
        "        df['Reviewed'] = False\n",
        "    df.to_csv(csv_path, index_label='id', encoding='utf-16')\n",
        "\n",
        "# Call the function with debug=True for additional output\n",
        "add_columns_to_csv(debug=True)\n",
        "\n",
        "# Load the updated dataframe\n",
        "df = pd.read_csv(csv_path, index_col='id', encoding='utf-16')\n",
        "\n",
        "# Folder containing the WAV files\n",
        "audio_folder_path = voice_data\n",
        "\n",
        "# Load the audio and corresponding text\n",
        "def load_audio_and_text(index):\n",
        "    audio_path = os.path.join(audio_folder_path, f\"{index}.wav\")\n",
        "    if not os.path.exists(audio_path):\n",
        "        return None, \"Audio file does not exist.\", \"\"\n",
        "    text = df.loc[index, 'transcription'] if index in df.index else \"Text not found.\"\n",
        "    return audio_path, text, f\"{index}.wav\"\n",
        "\n",
        "# Save the edited text, mark as edited in the CSV, and mark as reviewed\n",
        "def save_text(index, text, original_text):\n",
        "    if 0 < index <= df.index.max() and df.at[index, 'transcription'] != text:\n",
        "        df.at[index, 'transcription'] = text\n",
        "        df.at[index, 'Edited'] = True  # Mark as edited\n",
        "        df.at[index, 'Reviewed'] = True  # Mark as reviewed\n",
        "        df.to_csv(csv_path, encoding='utf-16')\n",
        "\n",
        "# Gradio app interface\n",
        "with gr.Blocks(theme=\"dark\") as app:\n",
        "    gr.Markdown(\"## Start Annotation From WAV File Number\")\n",
        "    start_from = gr.Number(label=\"Start From WAV Number\", value=1)\n",
        "\n",
        "    gr.Markdown(\"## Voice Data Annotation System\")\n",
        "    gr.Markdown(\"### Please annotate the following voice data\")\n",
        "    wav_file_name = gr.Label(label=\"WAV File Name\")\n",
        "    audio_player = gr.Audio()\n",
        "    annotation_area = gr.Textbox(label=\"Annotation Area\")\n",
        "    index_state = gr.Number(value=1, label=\"Index\", visible=False)\n",
        "    edited_marker = gr.Label(value=\"\", label=\"Edited Status\", visible=False)\n",
        "\n",
        "    def update_interface(index, text, direction):\n",
        "        original_text = df.loc[index, 'transcription'] if index in df.index else \"\"\n",
        "        save_text(index, text, original_text)\n",
        "\n",
        "        if direction == 'next':\n",
        "            index += 1\n",
        "        elif direction == 'previous':\n",
        "            index = max(1, index - 1)\n",
        "\n",
        "        new_audio_path, new_text, file_name = load_audio_and_text(index)\n",
        "        edited = df.loc[index, 'Edited'] if index in df.index else False\n",
        "\n",
        "        edited_status = \"✅ Edited\" if edited else \"\"\n",
        "\n",
        "        return new_audio_path, new_text, index, edited_status, file_name\n",
        "\n",
        "    def initialize_interface(start_index):\n",
        "        new_audio_path, new_text, file_name = load_audio_and_text(start_index)\n",
        "        edited = df.loc[start_index, 'Edited'] if start_index in df.index else False\n",
        "        edited_status = \"✅ Edited\" if edited else \"\"\n",
        "        return new_audio_path, new_text, start_index, edited_status, file_name\n",
        "\n",
        "    start_from.change(initialize_interface, inputs=[start_from], outputs=[audio_player, annotation_area, index_state, edited_marker, wav_file_name])\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Button(\"Previous\").click(\n",
        "            lambda index, text: update_interface(index, text, 'previous'),\n",
        "            inputs=[index_state, annotation_area],\n",
        "            outputs=[audio_player, annotation_area, index_state, edited_marker, wav_file_name]\n",
        "        )\n",
        "        gr.Button(\"Next\").click(\n",
        "            lambda index, text: update_interface(index, text, 'next'),\n",
        "            inputs=[index_state, annotation_area],\n",
        "            outputs=[audio_player, annotation_area, index_state, edited_marker, wav_file_name]\n",
        "        )\n",
        "\n",
        "    # Apply custom CSS for layout adjustments\n",
        "    app.css = \".gr-textbox { height: 500px; } .gr-row { align-items: center; }\"\n",
        "\n",
        "app.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}